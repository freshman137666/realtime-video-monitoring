import cv2
import threading
import queue
import time
import uuid
import numpy as np  # æ·»åŠ numpyå¯¼å…¥
from typing import List, Dict, Optional
from threading import Event
from datetime import datetime
from app import socketio
from app.services.danger_zone import DANGER_ZONE
from ultralytics import YOLO
import base64

class RTMPStreamManager:
    def __init__(self):
        self.streams: Dict[str, dict] = {}
        self.active_captures: Dict[str, cv2.VideoCapture] = {}
        self.streaming_threads: Dict[str, threading.Thread] = {}
        self.analysis_threads: Dict[str, threading.Thread] = {}
        # ä¸ºæ¨æµå’Œåˆ†æåˆ›å»ºç‹¬ç«‹çš„é˜Ÿåˆ—
        self.streaming_queues: Dict[str, queue.Queue] = {}
        self.analysis_queues: Dict[str, queue.Queue] = {}
        self.stop_events: Dict[str, threading.Event] = {}
        self.reader_threads = {}
        
        # æ·»åŠ å§¿æ€å†å²è¿½è¸ª
        self.pose_history = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªäººçš„å§¿æ€å†å²
        
        # åˆå§‹åŒ–AIæ¨¡å‹
        print("æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹...")
        try:
            from app.services.detection import get_object_model, get_face_model, get_pose_model
            from app.services.dlib_service import dlib_face_service
            
            self.models = {
                'object': get_object_model(),
                'face': get_face_model(),
                'pose': get_pose_model()  # æ·»åŠ å§¿æ€æ¨¡å‹
            }
            self.dlib_service = dlib_face_service
            print("âœ… AIæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            # è®¾ç½®ä¸ºNoneä»¥é¿å…åç»­é”™è¯¯
            self.models = {
                'object': None,
                'face': None,
                'pose': None  # æ·»åŠ å§¿æ€æ¨¡å‹
            }
            self.dlib_service = None
    
    def add_stream(self, config: dict) -> str:
        """æ·»åŠ æ–°çš„RTMPæµ"""
        stream_id = str(uuid.uuid4())
        
        # ä¿å­˜æµé…ç½®
        self.streams[stream_id] = {
            'stream_id': stream_id,
            'name': config['name'],
            'rtmp_url': config['rtmp_url'],
            'description': config.get('description', ''),
            'detection_modes': config.get('detection_modes', ['object_detection']),
            'status': 'inactive',
            'created_at': datetime.now().isoformat(),
            'last_activity': None
        }
        
        return stream_id

    def start_stream(self, stream_id: str):
        """å¯åŠ¨RTMPæµå¤„ç†"""
        if stream_id not in self.streams:
            raise Exception("æµä¸å­˜åœ¨")
        
        stream_config = self.streams[stream_id]
        rtmp_url = stream_config['rtmp_url']
        
        print(f"å°è¯•å¯åŠ¨æµ: {stream_id}, URL: {rtmp_url}")
        
        # åˆ›å»ºVideoCapture
        cap = cv2.VideoCapture(rtmp_url)
        
        # è®¾ç½®ç¼“å†²åŒºå¤§å°å’Œè¶…æ—¶
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        if not cap.isOpened():
            raise Exception(f"æ— æ³•è¿æ¥åˆ°RTMPæµ: {rtmp_url}")
        
        # æµ‹è¯•è¯»å–ä¸€å¸§
        ret, frame = cap.read()
        if not ret:
            cap.release()
            raise Exception(f"æ— æ³•ä»RTMPæµè¯»å–æ•°æ®: {rtmp_url}")
        
        # è·å–åŸå§‹è§†é¢‘å°ºå¯¸
        original_height, original_width = frame.shape[:2]
        print(f"âœ… RTMPæµè¿æ¥æˆåŠŸï¼ŒåŸå§‹å°ºå¯¸: {original_width}x{original_height}")
        
        # ä¿å­˜åŸå§‹å°ºå¯¸åˆ°æµé…ç½®ä¸­
        self.streams[stream_id]['original_width'] = original_width
        self.streams[stream_id]['original_height'] = original_height
        
        # å­˜å‚¨captureå’Œç›¸å…³èµ„æº
        self.active_captures[stream_id] = cap
        self.stop_events[stream_id] = threading.Event()
        # åˆ›å»ºç‹¬ç«‹çš„é˜Ÿåˆ—
        self.streaming_queues[stream_id] = queue.Queue(maxsize=10)
        self.analysis_queues[stream_id] = queue.Queue(maxsize=5)
        
        # å¯åŠ¨å•ä¸€è¯»å–çº¿ç¨‹ï¼ˆè´Ÿè´£ä»RTMPæµè¯»å–å¸§ï¼‰
        reader_thread = threading.Thread(
            target=self._frame_reader_loop,
            args=(stream_id,),
            daemon=True
        )
        reader_thread.start()
        self.reader_threads[stream_id] = reader_thread
        
        # å¯åŠ¨æ¨æµçº¿ç¨‹ï¼ˆä»é˜Ÿåˆ—è·å–å¸§å¹¶å‘é€ï¼‰
        streaming_thread = threading.Thread(
            target=self._streaming_loop,
            args=(stream_id,),
            daemon=True
        )
        streaming_thread.start()
        self.streaming_threads[stream_id] = streaming_thread
        
        # å¯åŠ¨åˆ†æçº¿ç¨‹ï¼ˆä»é˜Ÿåˆ—è·å–å¸§å¹¶è¿›è¡ŒAIæ£€æµ‹ï¼‰
        analysis_thread = threading.Thread(
            target=self._analysis_loop,
            args=(stream_id,),
            daemon=True
        )
        analysis_thread.start()
        self.analysis_threads[stream_id] = analysis_thread
        
        # æ›´æ–°çŠ¶æ€
        self.streams[stream_id]['status'] = 'active'
        self.streams[stream_id]['last_activity'] = datetime.now().isoformat()
        
        print(f"âœ… æµ {stream_id} å¯åŠ¨æˆåŠŸ")

    def _frame_reader_loop(self, stream_id: str):
        """å¸§è¯»å–çº¿ç¨‹ï¼šä»RTMPæµè¯»å–å¸§å¹¶åˆ†å‘åˆ°ä¸¤ä¸ªé˜Ÿåˆ—"""
        cap = self.active_captures[stream_id]
        stop_event = self.stop_events[stream_id]
        streaming_queue = self.streaming_queues[stream_id]
        analysis_queue = self.analysis_queues[stream_id]
        
        print(f"ğŸ“– å¸§è¯»å–çº¿ç¨‹å¯åŠ¨: {stream_id}")
        
        consecutive_failures = 0
        max_failures = 10
        
        try:
            while not stop_event.is_set():
                ret, frame = cap.read()
                if not ret:
                    consecutive_failures += 1
                    print(f"å¸§è¯»å–å¤±è´¥ {stream_id}, è¿ç»­å¤±è´¥æ¬¡æ•°: {consecutive_failures}")
                    
                    if consecutive_failures >= max_failures:
                        print(f"è¿ç»­è¯»å–å¤±è´¥è¶…è¿‡{max_failures}æ¬¡ï¼Œåœæ­¢è¯»å–çº¿ç¨‹")
                        break
                    
                    time.sleep(0.1)
                    continue
                
                consecutive_failures = 0
                
                # å°†å¸§åˆ†å‘åˆ°ä¸¤ä¸ªé˜Ÿåˆ—
                frame_copy = frame.copy()
                
                # æ¨æµé˜Ÿåˆ—ï¼ˆé«˜é¢‘ç‡ï¼‰
                try:
                    streaming_queue.put(frame_copy, block=False)
                except queue.Full:
                    try:
                        streaming_queue.get_nowait()
                        streaming_queue.put(frame_copy, block=False)
                    except queue.Empty:
                        pass
                
                # åˆ†æé˜Ÿåˆ—ï¼ˆä½é¢‘ç‡ï¼Œæ¯5å¸§ä¸€æ¬¡ï¼‰
                if consecutive_failures == 0:  # åªæœ‰æˆåŠŸè¯»å–æ—¶æ‰è€ƒè™‘åˆ†æ
                    try:
                        analysis_queue.put(frame.copy(), block=False)
                    except queue.Full:
                        try:
                            analysis_queue.get_nowait()
                            analysis_queue.put(frame.copy(), block=False)
                        except queue.Empty:
                            pass
                
                time.sleep(0.033)
                
        except Exception as e:
            print(f"å¸§è¯»å–çº¿ç¨‹é”™è¯¯ {stream_id}: {e}")
        finally:
            print(f"ğŸ“– å¸§è¯»å–çº¿ç¨‹ç»“æŸ: {stream_id}")

    def _streaming_loop(self, stream_id: str):
        """æ¨æµçº¿ç¨‹ï¼šä»æ¨æµé˜Ÿåˆ—è·å–å¸§å¹¶å‘é€"""
        stop_event = self.stop_events[stream_id]
        streaming_queue = self.streaming_queues[stream_id]
        stream_config = self.streams[stream_id]
        
        print(f"ğŸ“º æ¨æµçº¿ç¨‹å¯åŠ¨: {stream_id}")
        
        frame_count = 0
        
        try:
            while not stop_event.is_set():
                try:
                    frame = streaming_queue.get(timeout=1.0)
                except queue.Empty:
                    continue
                
                frame_count += 1
                
                # ä¿æŒåŸå§‹åˆ†è¾¨ç‡ï¼Œä¸è¿›è¡Œresize
                # frame_resized = cv2.resize(frame, (640, 480))  # åˆ é™¤è¿™è¡Œ
                
                # å‹ç¼©ä¸ºJPEGï¼ˆè°ƒæ•´è´¨é‡ä»¥å¹³è¡¡æ–‡ä»¶å¤§å°å’Œç”»è´¨ï¼‰
                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                frame_bytes = buffer.tobytes()
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if frame_count % 30 == 0:  # æ¯30å¸§æ‰“å°ä¸€æ¬¡
                    print(f"ğŸ“º å‘é€ç¬¬{frame_count}å¸§ï¼Œå¤§å°: {len(frame_bytes)} bytes, æµID: {stream_id}")
                
                # é€šè¿‡Socket.IOå‘é€äºŒè¿›åˆ¶æ•°æ®ï¼ŒåŒ…å«åŸå§‹å°ºå¯¸ä¿¡æ¯
                try:
                    socketio.emit('video_frame', {
                        'stream_id': stream_id,
                        'frame_data': frame_bytes,
                        'frame_count': frame_count,
                        'timestamp': datetime.now().isoformat(),
                        'original_width': stream_config.get('original_width', 1280),
                        'original_height': stream_config.get('original_height', 720)
                    }, namespace='/rtmp')
                    
                    # æ·»åŠ å‘é€ç¡®è®¤æ—¥å¿—
                    if frame_count % 30 == 0:
                        print(f"âœ… å·²å‘é€video_frameäº‹ä»¶åˆ°/rtmpå‘½åç©ºé—´ï¼ŒæµID: {stream_id}, å¸§æ•°: {frame_count}")
                        
                except Exception as emit_error:
                    print(f"âŒ Socket.IOå‘é€é”™è¯¯: {emit_error}")
                
                # æ›´æ–°æ´»åŠ¨æ—¶é—´
                self.streams[stream_id]['last_activity'] = datetime.now().isoformat()
                
                time.sleep(0.033)  # çº¦30fps
                
        except Exception as e:
            print(f"æ¨æµçº¿ç¨‹é”™è¯¯ {stream_id}: {e}")
        finally:
            print(f"ğŸ“º æ¨æµçº¿ç¨‹ç»“æŸ: {stream_id}")

    def _analysis_loop(self, stream_id: str):
        """åˆ†æçº¿ç¨‹ï¼šä»åˆ†æé˜Ÿåˆ—è·å–å¸§å¹¶è¿›è¡ŒAIæ£€æµ‹"""
        stop_event = self.stop_events[stream_id]
        analysis_queue = self.analysis_queues[stream_id]
        stream_config = self.streams[stream_id]
        
        print(f"ğŸ” åˆ†æçº¿ç¨‹å¯åŠ¨: {stream_id}")
        
        frame_count = 0
        
        try:
            while not stop_event.is_set():
                try:
                    frame = analysis_queue.get(timeout=1.0)
                except queue.Empty:
                    continue
                
                frame_count += 1
                
                # æ¯3å¸§è¿›è¡Œä¸€æ¬¡AIæ£€æµ‹
                if frame_count % 3 == 0:
                    try:
                        detection_results = self._perform_detection(
                            frame, stream_config['detection_modes']
                        )
                        
                        socketio.emit('ai_result', {
                            'stream_id': stream_id,
                            'timestamp': datetime.now().isoformat(),
                            'detections': detection_results['detections'],
                            'alerts': detection_results['alerts']
                        }, namespace='/rtmp', room=stream_id)
                        
                    except Exception as e:
                        print(f"AIæ£€æµ‹é”™è¯¯: {e}")
                
                time.sleep(0.1)
                
        except Exception as e:
            print(f"åˆ†æçº¿ç¨‹é”™è¯¯ {stream_id}: {e}")
        finally:
            print(f"ğŸ” åˆ†æçº¿ç¨‹ç»“æŸ: {stream_id}")

    def _perform_detection(self, frame, detection_modes):
        """æ‰§è¡ŒAIæ£€æµ‹"""
        results = {'detections': [], 'alerts': []}
        
        try:
            # ç›®æ ‡æ£€æµ‹
            if 'object_detection' in detection_modes and self.models.get('object') is not None:
                object_results = self.models['object'](frame)
                for result in object_results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            
                            if conf > 0.5:
                                class_name = self.models['object'].names[cls]
                                results['detections'].append({
                                    'type': 'object',
                                    'class': class_name,
                                    'confidence': float(conf),
                                    'bbox': [int(x1), int(y1), int(x2), int(y2)]
                                })
                                
                                if self._is_in_danger_zone(x1, y1, x2, y2):
                                    results['alerts'].append(f'æ£€æµ‹åˆ°{class_name}è¿›å…¥å±é™©åŒºåŸŸï¼')
            
            # äººè„¸æ£€æµ‹å’Œè¯†åˆ«
            if 'face_only' in detection_modes and self.models.get('face') is not None:
                face_results = self.models['face'](frame)
                for result in face_results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            
                            if conf > 0.5:
                                results['detections'].append({
                                    'type': 'face',
                                    'confidence': float(conf),
                                    'bbox': [int(x1), int(y1), int(x2), int(y2)]
                                })
                                
                                if 'face_only' in detection_modes:
                                    if self.dlib_service:
                                        face_crop = frame[int(y1):int(y2), int(x1):int(x2)]
                                        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•åå’Œå‚æ•°æ ¼å¼
                                        face_boxes = [[int(x1), int(y1), int(x2), int(y2)]]
                                        recognition_results = self.dlib_service.identify_faces(frame, face_boxes)
                                        if recognition_results and len(recognition_results) > 0:
                                            name, bbox = recognition_results[0]
                                            if name != "Unknown":
                                                results['detections'][-1]['name'] = name
                                            else:
                                                results['detections'][-1]['name'] = "stranger"
            
            # è·Œå€’æ£€æµ‹éƒ¨åˆ†ä¿®å¤
            if 'fall_detection' in detection_modes and self.models.get('pose') is not None:
                try:
                    # è¿›è¡Œå§¿æ€ä¼°è®¡
                    pose_results = self.models['pose'](frame)
                    
                    if pose_results and len(pose_results) > 0:
                        # ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹å’Œéª¨æ¶
                        annotated_frame = pose_results[0].plot()  # æ·»åŠ è¿™è¡Œæ¥ç»˜åˆ¶å¯è§†åŒ–
                        
                        for result in pose_results:
                            if result.keypoints is not None:
                                keypoints = result.keypoints.data.cpu().numpy()
                                
                                for person_keypoints in keypoints:
                                    # è®¡ç®—è¾¹ç•Œæ¡†
                                    bbox = self._get_pose_bbox(person_keypoints)
                                    
                                    # è·Œå€’æ£€æµ‹é€»è¾‘
                                    fall_detected, confidence = self._detect_fall(person_keypoints)
                                    
                                    if fall_detected:
                                        results['detections'].append({
                                            'type': 'fall',
                                            'confidence': confidence,
                                            'bbox': bbox,
                                            'keypoints': person_keypoints.tolist(),  # æ·»åŠ å…³é”®ç‚¹æ•°æ®
                                            'message': 'æ£€æµ‹åˆ°è·Œå€’ï¼'
                                        })
                                        results['alerts'].append('æ£€æµ‹åˆ°è·Œå€’è¡Œä¸ºï¼')
                                    else:
                                        # å³ä½¿æ²¡æœ‰è·Œå€’ä¹Ÿè¿”å›å§¿æ€æ•°æ®ç”¨äºå¯è§†åŒ–
                                        results['detections'].append({
                                            'type': 'pose',
                                            'confidence': 0.8,
                                            'bbox': bbox,
                                            'keypoints': person_keypoints.tolist(),
                                            'message': 'æ­£å¸¸å§¿æ€'
                                        })
                
                except Exception as e:
                    print(f"è·Œå€’æ£€æµ‹é”™è¯¯: {e}")
                
                return results
            results['detections'].extend(fall_results['detections'])
            results['alerts'].extend(fall_results['alerts'])
            
        except Exception as e:
            print(f"AIæ£€æµ‹é”™è¯¯: {e}")
        
        return results
    
    def _process_smoking_detection(self, frame):
        """å¤„ç†æŠ½çƒŸæ£€æµ‹ - å¢å¼ºç‰ˆ"""
        results = {'detections': [], 'alerts': []}
        
        try:
            # æ–¹æ³•1ï¼šä½¿ç”¨ä¸“ç”¨æŠ½çƒŸæ£€æµ‹æ¨¡å‹
            if hasattr(self, 'smoking_model') and self.smoking_model is not None:
                smoking_results = self.smoking_model(frame)
                
                for result in smoking_results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            
                            if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                                results['detections'].append({
                                    'type': 'smoking',
                                    'confidence': float(conf),
                                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                    'message': 'æ£€æµ‹åˆ°å¸çƒŸè¡Œä¸º'
                                })
                                results['alerts'].append('æ£€æµ‹åˆ°å¸çƒŸè¡Œä¸ºï¼')
                            
            # æ–¹æ³•2ï¼šå¤‡ç”¨æ£€æµ‹ - ä½¿ç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹æ£€æµ‹é¦™çƒŸç›¸å…³ç‰©ä½“
            elif self.models.get('object') is not None:
                object_results = self.models['object'](frame)
                
                # å®šä¹‰ä¸å¸çƒŸç›¸å…³çš„ç±»åˆ«ï¼ˆæ ¹æ®COCOæ•°æ®é›†ï¼‰
                smoking_related_classes = ['person']  # å¯ä»¥æ‰©å±•ä¸ºåŒ…å«é¦™çƒŸã€æ‰“ç«æœºç­‰
                
                for result in object_results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            class_name = self.models['object'].names[cls]
                            
                            if conf > 0.6 and class_name in smoking_related_classes:
                                # æå–äººç‰©åŒºåŸŸè¿›è¡Œè¿›ä¸€æ­¥åˆ†æ
                                person_crop = frame[int(y1):int(y2), int(x1):int(x2)]
                                
                                # ç®€å•çš„å¯å‘å¼æ£€æµ‹ï¼ˆå¯ä»¥ç”¨æ›´å¤æ‚çš„ç®—æ³•æ›¿æ¢ï¼‰
                                if self._detect_smoking_heuristic(person_crop):
                                    results['detections'].append({
                                        'type': 'smoking_suspected',
                                        'confidence': float(conf * 0.7),  # é™ä½ç½®ä¿¡åº¦
                                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                        'message': 'ç–‘ä¼¼å¸çƒŸè¡Œä¸º'
                                    })
                                    results['alerts'].append('ç–‘ä¼¼æ£€æµ‹åˆ°å¸çƒŸè¡Œä¸ºï¼')
        
        except:
            pass
        
        return results
    
    def _detect_smoking_heuristic(self, person_crop):
        """ç®€å•çš„å¯å‘å¼å¸çƒŸæ£€æµ‹"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°ç®€å•çš„å›¾åƒå¤„ç†é€»è¾‘
            # ä¾‹å¦‚ï¼šæ£€æµ‹æ‰‹éƒ¨åŒºåŸŸçš„äº®ç‚¹ã€çƒŸé›¾æ¨¡ç³Šç­‰
            # ç›®å‰è¿”å›éšæœºç»“æœä½œä¸ºç¤ºä¾‹
            import random
            return random.random() > 0.8  # 20%çš„æ¦‚ç‡æ£€æµ‹ä¸ºå¸çƒŸ
        except:
            return False
    
    def _process_violence_detection(self, frame):
        """å¤„ç†æš´åŠ›æ£€æµ‹"""
        results = {'detections': [], 'alerts': []}
        
        try:
            # è¿™é‡Œå¯ä»¥å®ç°æš´åŠ›æ£€æµ‹é€»è¾‘
            # ç›®å‰è¿”å›ç©ºç»“æœä½œä¸ºç¤ºä¾‹
            return results
        except Exception as e:
            print(f"æš´åŠ›æ£€æµ‹é”™è¯¯: {e}")
            return results
    
    def _predict_violence(self, frame_sequence):
        """é¢„æµ‹æš´åŠ›è¡Œä¸º"""
        try:
            if not hasattr(self, 'violence_model') or self.violence_model is None or not hasattr(self, 'image_model_transfer') or self.image_model_transfer is None:
                return 0.0
                
            import tensorflow as tf
            import numpy as np
            
            # å°†å¸§åºåˆ—è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
            frames = np.array(frame_sequence)
            
            # ä½¿ç”¨VGG16æå–ç‰¹å¾
            features = []
            for frame in frames:
                # è°ƒæ•´å¸§å¤§å°ä¸ºVGG16è¾“å…¥è¦æ±‚
                resized_frame = tf.image.resize(frame, [224, 224])
                resized_frame = tf.expand_dims(resized_frame, 0)
                feature = self.image_model_transfer.predict(resized_frame, verbose=0)
                features.append(feature[0])
            
            # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
            features = np.array(features)
            features = np.expand_dims(features, 0)
            
            # é¢„æµ‹æš´åŠ›æ¦‚ç‡
            prediction = self.violence_model.predict(features, verbose=0)
            violence_prob = prediction[0][1] if len(prediction[0]) > 1 else prediction[0][0]
            
            return float(violence_prob)
            
        except Exception as e:
            print(f"æš´åŠ›é¢„æµ‹é”™è¯¯: {e}")
            return 0.0
    
    def _get_pose_bbox(self, keypoints):
        """ä»å…³é”®ç‚¹è®¡ç®—è¾¹ç•Œæ¡†"""
        try:
            # è¿‡æ»¤æœ‰æ•ˆå…³é”®ç‚¹ï¼ˆåæ ‡å¤§äº0ï¼‰
            valid_points = keypoints[keypoints[:, 0] > 0]
            
            if len(valid_points) == 0:
                return [0, 0, 100, 100]  # é»˜è®¤è¾¹ç•Œæ¡†
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x_min = int(np.min(valid_points[:, 0]))
            y_min = int(np.min(valid_points[:, 1]))
            x_max = int(np.max(valid_points[:, 0]))
            y_max = int(np.max(valid_points[:, 1]))
            
            # æ·»åŠ ä¸€äº›è¾¹è·
            margin = 10
            x_min = max(0, x_min - margin)
            y_min = max(0, y_min - margin)
            x_max += margin
            y_max += margin
            
            return [x_min, y_min, x_max, y_max]
            
        except Exception as e:
            print(f"è®¡ç®—å§¿æ€è¾¹ç•Œæ¡†é”™è¯¯: {e}")
            return [0, 0, 100, 100]
    
    def _is_in_danger_zone(self, x1, y1, x2, y2):
        """æ£€æŸ¥æ˜¯å¦åœ¨å±é™©åŒºåŸŸå†…"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å±é™©åŒºåŸŸæ£€æµ‹é€»è¾‘
            # ç›®å‰è¿”å›Falseä½œä¸ºç¤ºä¾‹
            return False
        except Exception as e:
            print(f"å±é™©åŒºåŸŸæ£€æµ‹é”™è¯¯: {e}")
            return False
    
    def _detect_fall(self, keypoints):
        """æ£€æµ‹è·Œå€’è¡Œä¸º"""
        try:
            import numpy as np
            
            # è¿‡æ»¤æœ‰æ•ˆå…³é”®ç‚¹ï¼ˆç½®ä¿¡åº¦ > 0.5ï¼‰
            valid_keypoints = []
            for i, kp in enumerate(keypoints):
                if len(kp) >= 3 and kp[2] > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                    valid_keypoints.append([kp[0], kp[1], i])  # [x, y, keypoint_index]
            
            if len(valid_keypoints) < 5:  # éœ€è¦è¶³å¤Ÿçš„å…³é”®ç‚¹
                return False, 0.0
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ä¾¿äºè®¡ç®—
            points = np.array([[kp[0], kp[1]] for kp in valid_keypoints])
            
            # è®¡ç®—äººä½“è¾¹ç•Œæ¡†
            x_min, y_min = np.min(points, axis=0)
            x_max, y_max = np.max(points, axis=0)
            
            # è®¡ç®—å®½é«˜æ¯”
            width = x_max - x_min
            height = y_max - y_min
            
            if height == 0:
                return False, 0.0
                
            aspect_ratio = width / height
            
            # è·Œå€’åˆ¤æ–­é€»è¾‘
            fall_confidence = 0.0
            
            # 1. å®½é«˜æ¯”æ£€æµ‹ï¼ˆè·Œå€’æ—¶äººä½“æ›´å®½ï¼‰
            if aspect_ratio > 1.2:  # å®½åº¦å¤§äºé«˜åº¦
                fall_confidence += 0.4
            
            # 2. å¤´éƒ¨ä½ç½®æ£€æµ‹ï¼ˆå¦‚æœèƒ½æ£€æµ‹åˆ°å¤´éƒ¨å’Œèº¯å¹²ï¼‰
            head_points = [kp for kp in valid_keypoints if kp[2] in [0, 1, 2, 3, 4]]  # å¤´éƒ¨å…³é”®ç‚¹
            body_points = [kp for kp in valid_keypoints if kp[2] in [5, 6, 11, 12]]  # èº¯å¹²å…³é”®ç‚¹
            
            if head_points and body_points:
                head_y = np.mean([kp[1] for kp in head_points])
                body_y = np.mean([kp[1] for kp in body_points])
                
                # å¤´éƒ¨åº”è¯¥åœ¨èº¯å¹²ä¸Šæ–¹ï¼Œå¦‚æœä¸æ˜¯å¯èƒ½è·Œå€’äº†
                if abs(head_y - body_y) < height * 0.3:  # å¤´éƒ¨å’Œèº¯å¹²åœ¨åŒä¸€æ°´å¹³çº¿
                    fall_confidence += 0.3
            
            # 3. æ•´ä½“å§¿æ€è§’åº¦æ£€æµ‹
            if len(points) >= 2:
                # è®¡ç®—ä¸»è½´è§’åº¦
                center = np.mean(points, axis=0)
                centered_points = points - center
                
                # ä½¿ç”¨PCAè®¡ç®—ä¸»æ–¹å‘
                cov_matrix = np.cov(centered_points.T)
                eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
                
                # ä¸»æ–¹å‘å‘é‡
                main_direction = eigenvectors[:, -1]
                
                # è®¡ç®—ä¸å‚ç›´æ–¹å‘çš„è§’åº¦
                vertical = np.array([0, 1])
                angle = np.arccos(np.abs(np.dot(main_direction, vertical)))
                angle_degrees = np.degrees(angle)
                
                # å¦‚æœè§’åº¦å¤§äº45åº¦ï¼Œå¯èƒ½æ˜¯è·Œå€’
                if angle_degrees > 45:
                    fall_confidence += 0.3
            
            # åˆ¤æ–­æ˜¯å¦è·Œå€’
            is_fall = fall_confidence > 0.6
            
            return is_fall, min(fall_confidence, 1.0)
            
        except Exception as e:
            print(f"è·Œå€’æ£€æµ‹é”™è¯¯: {e}")
            return False, 0.0

    def stop_stream(self, stream_id: str):
        """åœæ­¢RTMPæµå¤„ç†"""
        if stream_id not in self.streams:
            raise Exception("æµä¸å­˜åœ¨")
        
        print(f"æ­£åœ¨åœæ­¢æµ: {stream_id}")
        
        # è®¾ç½®åœæ­¢äº‹ä»¶
        if stream_id in self.stop_events:
            self.stop_events[stream_id].set()
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if stream_id in self.reader_threads:
            self.reader_threads[stream_id].join(timeout=5)
            del self.reader_threads[stream_id]
        
        if stream_id in self.streaming_threads:
            self.streaming_threads[stream_id].join(timeout=5)
            del self.streaming_threads[stream_id]
        
        if stream_id in self.analysis_threads:
            self.analysis_threads[stream_id].join(timeout=5)
            del self.analysis_threads[stream_id]
        
        # é‡Šæ”¾èµ„æº
        if stream_id in self.active_captures:
            self.active_captures[stream_id].release()
            del self.active_captures[stream_id]
        
        # æ¸…ç†é˜Ÿåˆ—å’Œäº‹ä»¶
        if stream_id in self.streaming_queues:
            del self.streaming_queues[stream_id]
        
        if stream_id in self.analysis_queues:
            del self.analysis_queues[stream_id]
        
        if stream_id in self.stop_events:
            del self.stop_events[stream_id]
        
        # æ›´æ–°çŠ¶æ€
        self.streams[stream_id]['status'] = 'inactive'
        
        print(f"âœ… æµ {stream_id} å·²åœæ­¢")
    
    def get_stream_status(self, stream_id: str) -> dict:
        """è·å–æµçŠ¶æ€"""
        if stream_id not in self.streams:
            raise Exception("æµä¸å­˜åœ¨")
        
        return self.streams[stream_id]
    
    def list_streams(self) -> List[dict]:
        """åˆ—å‡ºæ‰€æœ‰æµ"""
        return list(self.streams.values())
    
    def remove_stream(self, stream_id: str):
        """ç§»é™¤æµ"""
        if stream_id not in self.streams:
            raise Exception("æµä¸å­˜åœ¨")
        
        # å¦‚æœæµæ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å®ƒ
        if self.streams[stream_id]['status'] == 'active':
            self.stop_stream(stream_id)
        
        # åˆ é™¤æµé…ç½®
        del self.streams[stream_id]
        
        print(f"âœ… æµ {stream_id} å·²ç§»é™¤")
    
    def get_all_streams(self) -> List[dict]:
        """è·å–æ‰€æœ‰æµï¼ˆå…¼å®¹æ–¹æ³•ï¼‰"""
        return self.list_streams()
    
    def delete_stream(self, stream_id: str):
        """åˆ é™¤æµï¼ˆå…¼å®¹æ–¹æ³•ï¼‰"""
        return self.remove_stream(stream_id)
    
    def get_stream_frames(self, stream_id: str):
        """è·å–æµå¸§æ•°æ®ï¼ˆç”¨äºHTTPæµï¼‰"""
        # è¿™ä¸ªæ–¹æ³•ç”¨äºHTTPè§†é¢‘æµï¼ŒRTMPæµä½¿ç”¨Socket.IO
        # å¯ä»¥è¿”å›ç©ºç”Ÿæˆå™¨æˆ–æŠ›å‡ºå¼‚å¸¸
        raise Exception("RTMPæµä½¿ç”¨Socket.IOä¼ è¾“ï¼Œä¸æ”¯æŒHTTPæµ")
    
    # åˆ›å»ºå…¨å±€å®ä¾‹ï¼ˆç§»åˆ°ç±»å®šä¹‰å¤–éƒ¨ï¼‰
rtmp_manager = RTMPStreamManager()